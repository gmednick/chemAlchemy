---
title: Iris Classification
author: 'Gabe Mednick'
date: '2020-10-21'
slug: iris-classification
categories: []
tags:
  - machine learning
  - tidymodels
subtitle: ''
summary: 'Flower classification using Tidymodels'
authors: []
lastmod: '2020-10-21T15:11:02-07:00'
featured: no
disable_jquery: no
image:
  caption: '[Photo by J Lee on Unsplash](https://unsplash.com/photos/uDe1HrcO2Tc)'
  focal_point: ''
  preview_only: false
projects: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(janitor)
library(knitr)
data("iris")
```

# The iris dataset
The iris dataset is a classic, so much so that it is one of the example datasets that is included with base R. You can use the `data()` function to access a complete list of datasets that come with R. There are often datasets associated with packages as well. For example, the Ames housing dataset is included with Tidymodels.

Let's take a look at the data.
```{r}
# load the iris data set
iris_df<- iris %>% 
  clean_names() 

iris_df %>%  head()

iris_df %>%  count(species)
# equal number of each species, 150 total
iris_df %>%  str()
# No NAs! this data is lickedy clean!

```
We see that we have four features (sepal length and with, and petal length and width) and there are three unique species.. 

**It makes sense to create a model that predicts the species of iris based on the flower's measurements.** 

# Visualize relationships
Before we do any kind of machine learning, let's visualize the relationships in our data and get a feel for the predictive power of our features. We can do this by plotting the explanatory features and then use color or faceting to create the distinction of species.

```{r}
iris_df %>% 
  ggplot(aes(sepal_length, sepal_width, color = species)) +
  geom_point() + facet_wrap(~species)

iris_df %>% 
  ggplot(aes(petal_length, petal_width, color = species)) +
  geom_point() + facet_wrap(~species)

```

# Tidy format
Let's change the shape of our data by combining all iris features into a single category called `metric` and the associated values will be assigned to a column that we name `value`. This tidy format lends itself to data visualization and many other tools in the tidyverse.

```{r}

iris_df_long <- iris_df %>%  
  pivot_longer(cols = sepal_length:petal_width,
               names_to = 'metric',
               values_to ='value') 

iris_df_long %>% 
  ggplot(aes(value, metric, color = species)) +
  geom_boxplot() + coord_flip()

iris_df_long %>%
  ggplot(aes(value, fill = species)) +
  geom_histogram(bins = 20, alpha = 0.7) +
  facet_wrap(~ metric, scales = "free_x")

iris_df_long %>% 
  ggplot(aes(value, fill = species)) +
  geom_density(alpha = .5) +
  facet_wrap(~ metric, scales = "free")

iris_df_long %>%
  ggplot(aes(species, value, color = species)) +
  geom_boxplot(alpha = 0.3) +
  facet_wrap(~ metric, scales = "free_y")
```

# Got models 
Before we get to modeling, we will want to split the data and typically some feature engineering may be necessary as well. Since our dataset is small, we are going to take the training set and make 25 bootstrap resamples. By default, `initial split` provides a 75:25 split for our train and test sets respectively. The function `bootstraps` will take the training data, further split it into a training and test set, then resample and repeat 25 times. This 'resampling' provides a more robust method to test our model validity.
```{r}
set.seed(123)
tidy_split <- initial_split(iris_df)
tidy_split
iris_train <- training(tidy_split)
iris_test <- testing(tidy_split)

iris_boots <- bootstraps(iris_train) 
iris_boots
```

# Recipes 
Is the way to go for feature engineering. A great way to see the available functions in a package is to type the package name and two colons, eg `recipes::` into the Rstudio console. All package functions will pop up and a brief description for the highlighted function will be available. 

![](recipes_functions.jpg)

Let's create a recipe to demonstrate how easy it is to apply feature engineering. Since the features of the iris dataset don't actually need any feature engineering, we won't include this recipe in our final workflow. 

```{r}
iris_rec <- recipe(species ~., data = iris_train) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

prep <-  prep(iris_rec)

kable(head(iris_juice <- juice(prep)))
```

# Creating models with the Recipes package
Let's set up two different models: first up **generalized linear model** or **glmnet**  
```{r}
set.seed(1234)
glmnet_mod <- multinom_reg(penalty = 0) %>% set_engine("glmnet") %>% 
  set_mode("classification")
glmnet_mod

glmnet_wf <- workflow() %>%
  add_formula(species ~ .) 
glmnet_wf

glmnet_results <- glmnet_wf %>%
  add_model(glmnet_mod) %>% 
  fit_resamples(
    resamples = iris_boots,
    control = control_resamples(extract = extract_model,
                             save_pred = TRUE)
    )
glmnet_results

collect_metrics(glmnet_results)
```
Now let's set up a **random forest** model. We can use the exact same procedure and simply switch out the model.
```{r}
set.seed(1234)
rf_mod <- rand_forest() %>%
  set_engine("ranger") %>%
  set_mode("classification")

# We set up a workflow and add the parts of our model together like legos
rf_wf <- workflow() %>%
  add_formula(species ~ .)

# Here we fit our 25 resampled datasets 
rf_results <- rf_wf %>%
  add_model(rf_mod) %>% 
  fit_resamples(
    resamples = iris_boots,
    control = control_resamples(save_pred = TRUE)
    )
collect_metrics(rf_results)
```

Here is a look at the confusion matrix summaries for our model. The confusion matrix let's us see the correct and incorrect predictions of our models in a single table.
```{r}
glmnet_results %>%
  conf_mat_resampled() 

rf_results %>%
  conf_mat_resampled() 
```

The ROC curve helps us visually interpret our model performance at every threshold.
```{r}
glmnet_results %>%
  collect_predictions() %>%
  group_by(id) %>%
  roc_curve(species, .pred_setosa:.pred_virginica) %>%
  autoplot()
  
```
```{r}
rf_results %>%
  collect_predictions() %>%
  group_by(id) %>%
  roc_curve(species, .pred_setosa:.pred_virginica) %>%
  autoplot() +
  theme(legend.position = 'none')

```
This is the final fit. By using the `last_fit(tidy_split)`, we are able to train our model on the training set and test the model on the testing set in one fell swoop!
```{r}
final_glmnet <- glmnet_wf %>%
    add_model(glmnet_mod) %>%
    last_fit(tidy_split)

final_glmnet

final_rf <- rf_wf %>%
    add_model(rf_mod) %>%
    last_fit(tidy_split)

final_rf
```
The confusion matrix was generated with the samples in the test data. Although the iris dataset is great for diving into the tidymodels-sphere, it does not present a real challenge for our model and results in near-perfect prediction.

```{r}
collect_metrics(final_glmnet)

collect_predictions(final_glmnet) %>%
  conf_mat(species, .pred_class) %>% 
  autoplot(type = 'heatmap')
```
```{r}
collect_metrics(final_rf)

collect_predictions(final_rf) %>%
  conf_mat(species, .pred_class) %>% 
  autoplot(type = 'heatmap')

```


```{r}
final_glmnet$.workflow[[1]] %>%
  tidy(exponentiate = TRUE) %>% 
  arrange(desc(estimate))

```
# Credits
I would like to thank my mentors, the three noble Jedi Knights of the tidyverse and tidymodels: Julia Silge, David Robinson and Andrew Couch. 