---
title: Iris Classification
author: 'Gabe Mednick'
date: '2020-10-21'
slug: iris-classification
categories: []
tags:
  - machine learning
  - tidymodels
subtitle: ''
summary: 'Flower classification using Tidymodels'
authors: []
lastmod: '2020-10-21T15:11:02-07:00'
featured: no
disable_jquery: no
image:
  caption: '[Photo by J Lee on Unsplash](https://unsplash.com/photos/uDe1HrcO2Tc)'
  focal_point: ''
  preview_only: false
projects: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(janitor)
library(knitr)
data("iris")
```

# The iris dataset
The iris dataset is a classic, so much so that it is built into datasets R. You can use `data()` in the R console to see a complete list of available datasets.  

```{r}
# load the iris data set
iris_df<- iris %>% 
  clean_names() 

# iris_df %>%  View()

iris_df %>%  count(species)
# equal number of each species, 150 total
iris_df %>%  summary()
# No NAs, the data is clean!

```

# Visualize relationships
Before we do any kind of machine learning, let's visualize the features and start thinking about what kind of questions we can ask. And 'see' how our features correlate which will also tell us about how well we will be able to make predictions with our data.
```{r}
iris_df %>% 
  ggplot(aes(sepal_length, sepal_width, color = species)) +
  geom_point() + facet_wrap(~species)

iris_df %>% 
  ggplot(aes(petal_length, petal_width, color = species)) +
  geom_point() + facet_wrap(~species)

```

# Tidy format
Let's change the shape of our data by combining all iris features into a single category called `metric` and the associated values will go into a column that we name `value`. 

```{r}

iris_df_long <- iris_df %>%  
  pivot_longer(cols = sepal_length:petal_width,
               names_to = 'metric',
               values_to ='value') 

iris_df_long %>% 
  ggplot(aes(value, metric, color = species)) +
  geom_boxplot() + coord_flip()

iris_df_long %>%
  ggplot(aes(value, fill = species)) +
  geom_histogram(bins = 20, alpha = 0.7) +
  facet_wrap(~ metric, scales = "free_x")

iris_df_long %>% 
  ggplot(aes(value, fill = species)) +
  geom_density(alpha = .5) +
  facet_wrap(~ metric, scales = "free")

iris_df_long %>%
  ggplot(aes(species, value, color = species)) +
  geom_boxplot(alpha = 0.3) +
  facet_wrap(~ metric, scales = "free_y")
```

# Let's get modeling! 
First, we split the data. Since we only have 150 samples (50 for each iris species), we will also use bootstrap resampling.
```{r}
set.seed(123)
tidy_split <- initial_split(iris_df)
iris_train <- training(tidy_split)
iris_test <- testing(tidy_split)

iris_boots <- bootstraps(iris_train) 
```

# Recipes 
Is the way to go for feature engineering. A great way to see the available functions in a package is to type the package name and two colons, eg `recipes::` into the Rstudio console. All package functions will pop up and a brief description for the highlighted function will be available. Or you can simply use `?function` if you know the function and just need more details.
```{r}
iris_rec <- recipe(species ~., data = iris_train) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

prep <-  prep(iris_rec)

kable(head(iris_juice <- juice(prep)))
```

# Create models. 
Let's set up two different models: **logistic regression** and **random forest**.
```{r}
glm_mod <- logistic_reg() %>%
  set_engine("glm") %>% 
  set_mode('classification')

glm_mod <- multinom_reg(penalty = 0) %>% set_engine("glmnet") %>% 
  set_mode("classification")

glm_wf <- workflow() %>%
  add_formula(species ~ .) 

rf_mod <- rand_forest() %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_wf <- workflow() %>%
  add_formula(species ~ .)
 
```

```{r}
set.seed(1234)
glm_results <- glm_wf %>%
  add_model(glm_mod) %>% 
  fit_resamples(
    resamples = iris_boots,
    control = control_resamples(extract = extract_model,
                             save_pred = TRUE)
    )

collect_metrics(glm_results)

rf_results <- rf_wf %>%
  add_model(rf_mod) %>% 
  fit_resamples(
    resamples = iris_boots,
    control = control_resamples(save_pred = TRUE)
    )
collect_metrics(rf_results)
```
```{r}
glm_results %>%
  conf_mat_resampled() 

glm_results %>%
  conf_mat_resampled() 
```

```{r}
glm_results %>%
  collect_predictions() %>%
  group_by(id) %>%
  roc_curve(species, .pred_setosa:.pred_virginica) %>%
  autoplot()
  
```
```{r}
rf_results %>%
  collect_predictions() %>%
  group_by(id) %>%
  roc_curve(species, .pred_setosa:.pred_virginica) %>%
  autoplot() +
  theme(legend.position = 'none')

```

```{r}
final_glm <- glm_wf %>%
    add_model(glm_mod) %>%
    last_fit(tidy_split)

final_glm

final_rf <- rf_wf %>%
    add_model(rf_mod) %>%
    last_fit(tidy_split)

final_rf
```


```{r}
collect_metrics(final_glm)

collect_predictions(final_glm) %>%
  conf_mat(species, .pred_class) %>% 
  autoplot(type = 'heatmap')
```
```{r}
collect_metrics(final_rf)

collect_predictions(final_rf) %>%
  conf_mat(species, .pred_class) %>% 
  autoplot(type = 'heatmap')

```


```{r}
final_glm$.workflow[[1]] %>%
  tidy(exponentiate = TRUE) %>% 
  arrange(estimate)

```
