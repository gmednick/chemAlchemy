[{"authors":["gabe"],"categories":null,"content":"My journey into the physical and biological sciences started with a desire to study osteopathic medicine. In the process of completing a biochemistry and molecular biology degree, my interest in the structure and function of the human body grew into a fascination with the invisible structure and function of the cell. I developed a deep interest in both physical chemistry and biochemistry, and my curiosity resulted in a PhD focussed on sensory transduction pathways and light sensing mechanisms in bacteria. After finishing my PhD, I developed and implemented innovative teaching practices in chemistry and biology at the university level. More recently (2018-2020), I worked as a senior scientist for a small startup with an emphasis on DNA and RNA synthesis. I love hands-on research but my current professional passions are data science and bioinformatics. Data informed choices can provide insight, drive innovation and optimize decision making. My mission is to facilitate this process.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9d5326a2f1cf09d7e5a9f14131238744","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"My journey into the physical and biological sciences started with a desire to study osteopathic medicine. In the process of completing a biochemistry and molecular biology degree, my interest in the structure and function of the human body grew into a fascination with the invisible structure and function of the cell.","tags":null,"title":"","type":"authors"},{"authors":[],"categories":[],"content":" The iris dataset The iris dataset is a classic, so much so that it is built into datasets R. You can use data() in the R console to see a complete list of available datasets.\n# load the iris data set iris_df\u0026lt;- iris %\u0026gt;% clean_names() # iris_df %\u0026gt;% View() iris_df %\u0026gt;% count(species) ## species n ## 1 setosa 50 ## 2 versicolor 50 ## 3 virginica 50 # equal number of each species, 150 total iris_df %\u0026gt;% summary() ## sepal_length sepal_width petal_length petal_width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ##  # No NAs, the data is clean!  Visualize relationships Before we do any kind of machine learning, let’s visualize the features and start thinking about what kind of questions we can ask. And ‘see’ how our features correlate which will also tell us about how well we will be able to make predictions with our data.\niris_df %\u0026gt;% ggplot(aes(sepal_length, sepal_width, color = species)) + geom_point() + facet_wrap(~species) iris_df %\u0026gt;% ggplot(aes(petal_length, petal_width, color = species)) + geom_point() + facet_wrap(~species)  Tidy format Let’s change the shape of our data by combining all iris features into a single category called metric and the associated values will go into a column that we name value.\niris_df_long \u0026lt;- iris_df %\u0026gt;% pivot_longer(cols = sepal_length:petal_width, names_to = \u0026#39;metric\u0026#39;, values_to =\u0026#39;value\u0026#39;) iris_df_long %\u0026gt;% ggplot(aes(value, metric, color = species)) + geom_boxplot() + coord_flip() iris_df_long %\u0026gt;% ggplot(aes(value, fill = species)) + geom_histogram(bins = 20, alpha = 0.7) + facet_wrap(~ metric, scales = \u0026quot;free_x\u0026quot;) iris_df_long %\u0026gt;% ggplot(aes(value, fill = species)) + geom_density(alpha = .5) + facet_wrap(~ metric, scales = \u0026quot;free\u0026quot;) iris_df_long %\u0026gt;% ggplot(aes(species, value, color = species)) + geom_boxplot(alpha = 0.3) + facet_wrap(~ metric, scales = \u0026quot;free_y\u0026quot;)  Let’s get modeling! First, we split the data. Since we only have 150 samples (50 for each iris species), we will also use bootstrap resampling.\nset.seed(123) tidy_split \u0026lt;- initial_split(iris_df) iris_train \u0026lt;- training(tidy_split) iris_test \u0026lt;- testing(tidy_split) iris_boots \u0026lt;- bootstraps(iris_train)   Recipes Is the way to go for feature engineering. A great way to see the available functions in a package is to type the package name and two colons, eg recipes:: into the Rstudio console. All package functions will pop up and a brief description for the highlighted function will be available. Or you can simply use ?function if you know the function and just need more details.\niris_rec \u0026lt;- recipe(species ~., data = iris_train) %\u0026gt;% step_zv(all_predictors()) %\u0026gt;% step_normalize(all_predictors()) prep \u0026lt;- prep(iris_rec) kable(head(iris_juice \u0026lt;- juice(prep)))   sepal_length sepal_width petal_length petal_width species    -0.9406570 0.9308067 -1.330437 -1.280818 setosa  -1.2040875 -0.1535351 -1.330437 -1.280818 setosa  -1.4675181 0.2802016 -1.388618 -1.280818 setosa  -1.5992334 0.0633332 -1.272256 -1.280818 setosa  -1.0723722 1.1476751 -1.330437 -1.280818 setosa  -0.5455111 1.7982802 -1.155894 -1.018146 setosa     Create models. Let’s set up two different models: logistic regression and random forest.\nglm_mod \u0026lt;- logistic_reg() %\u0026gt;% set_engine(\u0026quot;glm\u0026quot;) %\u0026gt;% set_mode(\u0026#39;classification\u0026#39;) glm_mod \u0026lt;- multinom_reg(penalty = 0) %\u0026gt;% set_engine(\u0026quot;glmnet\u0026quot;) %\u0026gt;% set_mode(\u0026quot;classification\u0026quot;) glm_wf \u0026lt;- workflow() %\u0026gt;% add_formula(species ~ .) rf_mod \u0026lt;- rand_forest() %\u0026gt;% set_engine(\u0026quot;ranger\u0026quot;) %\u0026gt;% set_mode(\u0026quot;classification\u0026quot;) rf_wf \u0026lt;- workflow() %\u0026gt;% add_formula(species ~ .) set.seed(1234) glm_results \u0026lt;- glm_wf %\u0026gt;% add_model(glm_mod) %\u0026gt;% fit_resamples( resamples = iris_boots, control = control_resamples(extract = extract_model, save_pred = TRUE) ) collect_metrics(glm_results) ## # A tibble: 2 x 5 ## .metric .estimator mean n std_err ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 accuracy multiclass 0.944 25 0.00642 ## 2 roc_auc hand_till 0.987 25 0.00234 rf_results \u0026lt;- rf_wf %\u0026gt;% add_model(rf_mod) %\u0026gt;% fit_resamples( resamples = iris_boots, control = control_resamples(save_pred = TRUE) ) collect_metrics(rf_results) ## # A tibble: 2 x 5 ## .metric .estimator mean n std_err ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 accuracy multiclass 0.945 25 0.00764 ## 2 roc_auc hand_till 0.993 25 0.00126 glm_results %\u0026gt;% conf_mat_resampled()  ## # A tibble: 9 x 3 ## Prediction Truth Freq ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa setosa 13.3 ## 2 setosa versicolor 0 ## 3 setosa virginica 0 ## 4 versicolor setosa 0 ## 5 versicolor versicolor 12.2 ## 6 versicolor virginica 1 ## 7 virginica setosa 0 ## 8 virginica versicolor 1.24 ## 9 virginica virginica 12.4 glm_results %\u0026gt;% conf_mat_resampled()  ## # A tibble: 9 x 3 ## Prediction Truth Freq ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa setosa 13.3 ## 2 setosa versicolor 0 ## 3 setosa virginica 0 ## 4 versicolor setosa 0 ## 5 versicolor versicolor 12.2 ## 6 versicolor virginica 1 ## 7 virginica setosa 0 ## 8 virginica versicolor 1.24 ## 9 virginica virginica 12.4 glm_results %\u0026gt;% collect_predictions() %\u0026gt;% group_by(id) %\u0026gt;% roc_curve(species, .pred_setosa:.pred_virginica) %\u0026gt;% autoplot() rf_results %\u0026gt;% collect_predictions() %\u0026gt;% group_by(id) %\u0026gt;% roc_curve(species, .pred_setosa:.pred_virginica) %\u0026gt;% autoplot() + theme(legend.position = \u0026#39;none\u0026#39;) final_glm \u0026lt;- glm_wf %\u0026gt;% add_model(glm_mod) %\u0026gt;% last_fit(tidy_split) final_glm ## # Resampling results ## # Monte Carlo cross-validation (0.75/0.25) with 1 resamples ## # A tibble: 1 x 6 ## splits id .metrics .notes .predictions .workflow ## \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; ## 1 \u0026lt;split [113… train/test … \u0026lt;tibble [2 ×… \u0026lt;tibble [0 … \u0026lt;tibble [37 × … \u0026lt;workflo… final_rf \u0026lt;- rf_wf %\u0026gt;% add_model(rf_mod) %\u0026gt;% last_fit(tidy_split) final_rf ## # Resampling results ## # Monte Carlo cross-validation (0.75/0.25) with 1 resamples ## # A tibble: 1 x 6 ## splits id .metrics .notes .predictions .workflow ## \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; ## 1 \u0026lt;split [113… train/test … \u0026lt;tibble [2 ×… \u0026lt;tibble [0 … \u0026lt;tibble [37 × … \u0026lt;workflo… collect_metrics(final_glm) ## # A tibble: 2 x 3 ## .metric .estimator .estimate ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 accuracy multiclass 1 ## 2 roc_auc hand_till 1 collect_predictions(final_glm) %\u0026gt;% conf_mat(species, .pred_class) %\u0026gt;% autoplot(type = \u0026#39;heatmap\u0026#39;) collect_metrics(final_rf) ## # A tibble: 2 x 3 ## .metric .estimator .estimate ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 accuracy multiclass 0.973 ## 2 roc_auc hand_till 1 collect_predictions(final_rf) %\u0026gt;% conf_mat(species, .pred_class) %\u0026gt;% autoplot(type = \u0026#39;heatmap\u0026#39;) final_glm$.workflow[[1]] %\u0026gt;% tidy(exponentiate = TRUE) %\u0026gt;% arrange(estimate) ## Loading required package: Matrix ## ## Attaching package: \u0026#39;Matrix\u0026#39; ## The following objects are masked from \u0026#39;package:tidyr\u0026#39;: ## ## expand, pack, unpack ## Loaded glmnet 4.0-2 ## # A tibble: 15 x 4 ## class term estimate penalty ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 virginica (Intercept) -32.0 0 ## 2 setosa petal_length -6.48 0 ## 3 virginica sepal_width -5.89 0 ## 4 setosa sepal_length 0 0 ## 5 setosa petal_width 0 0 ## 6 versicolor sepal_width 0 0 ## 7 versicolor petal_length 0 0 ## 8 versicolor petal_width 0 0 ## 9 virginica sepal_length 0 0 ## 10 versicolor sepal_length 1.39 0 ## 11 setosa sepal_width 4.70 0 ## 12 virginica petal_length 8.12 0 ## 13 versicolor (Intercept) 10.7 0 ## 14 virginica petal_width 17.0 0 ## 15 setosa (Intercept) 21.3 0  ","date":1603238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603318262,"objectID":"517bb6adcf89c779300b0648b798dbfb","permalink":"/post/iris-classification/","publishdate":"2020-10-21T00:00:00Z","relpermalink":"/post/iris-classification/","section":"post","summary":"Flower classification using Tidymodels","tags":["machine learning","tidymodels"],"title":"Iris Classification","type":"post"},{"authors":[],"categories":[],"content":" Intro This data comes from the R4DS TidyTuesday project. There are five related datasets but we will only look at key_crop_yields dataset in this exploration. The data contains crop yield (tonnes per hectare) by country and year. Let’s get started by loading the packages that we will need for this analysis.\nNext up, let’s download the data from the R4DS Github account and take a look at it. There is the wonderful package, tidytuesdayR by Ellis Hughes, that allows one to load and explore the TidyTuesday data in the Rstudio viewer. We will use the readr package from the tidyverse using read_csv to import our data as a modern data frame or tibble.\n# Load the data with a readr function crop_yields \u0026lt;- read_csv(\u0026quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-01/key_crop_yields.csv\u0026quot;) # land_use \u0026lt;- read_csv(\u0026quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-01/land_use_vs_yield_change_in_cereal_production.csv\u0026quot;) %\u0026gt;% janitor::clean_names() # The skim function provides a great way to get an initial summary. I typically use View() as well to view the dataset in Rstudio skimr::skim(crop_yields)  Table 1: Data summary  Name crop_yields  Number of rows 13075  Number of columns 14  _______________________   Column type frequency:   character 2  numeric 12  ________________________   Group variables None    Variable type: character\n  skim_variable n_missing complete_rate min max empty n_unique whitespace    Entity 0 1.00 4 39 0 249 0  Code 1919 0.85 3 8 0 214 0    Variable type: numeric\n    skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist    Year 0 1.00 1990.37 16.73 1961.00 1976.00 1991.00 2005.00 2018.00 ▇▆▇▇▇  Wheat (tonnes per hectare) 4974 0.62 2.43 1.69 0.00 1.23 1.99 3.12 10.67 ▇▅▂▁▁  Rice (tonnes per hectare) 4604 0.65 3.16 1.85 0.20 1.77 2.74 4.16 10.68 ▇▇▃▁▁  Maize (tonnes per hectare) 2301 0.82 3.02 3.13 0.03 1.14 1.83 3.92 36.76 ▇▁▁▁▁  Soybeans (tonnes per hectare) 7114 0.46 1.45 0.75 0.00 0.86 1.33 1.90 5.95 ▇▇▂▁▁  Potatoes (tonnes per hectare) 3059 0.77 15.40 9.29 0.84 8.64 13.41 20.05 75.30 ▇▅▁▁▁  Beans (tonnes per hectare) 5066 0.61 1.09 0.82 0.03 0.59 0.83 1.35 9.18 ▇▁▁▁▁  Peas (tonnes per hectare) 6840 0.48 1.48 1.01 0.04 0.72 1.15 1.99 7.16 ▇▃▁▁▁  Cassava (tonnes per hectare) 5887 0.55 9.34 5.11 1.00 5.55 8.67 11.99 38.58 ▇▇▁▁▁  Barley (tonnes per hectare) 6342 0.51 2.23 1.50 0.09 1.05 1.88 3.02 9.15 ▇▆▂▁▁  Cocoa beans (tonnes per hectare) 8466 0.35 0.39 0.28 0.00 0.24 0.36 0.49 3.43 ▇▁▁▁▁  Bananas (tonnes per hectare) 4166 0.68 15.20 12.08 0.66 5.94 11.78 20.79 77.59 ▇▃▁▁▁    # Here are a few other options for getting to know our data # glimpse(crop_yields) # summary(crop_yields) # View(crop_yields)  Data cleaning and reshaping Let’s start with a little data cleaning! Using skim from skimr provides a convenient summary. We can see that there are plenty of NAs that we will most likely need to remove. We can also standardize our feature names with the janitor package. Lastly, we should consider the shape of our data and make sure that it’s in a tidy format where each column is a feature and each row a sample.This long or tidy format is a prerequisite for fluent analysis with the tidyverse and tidymodels frameworks. In our data example, the various crops on samples, that can be categorized as the feature crops. The function pivot_longer is fantastic function from the tidyr package that allows us to reshape our data and preparing it for This will benefit our downstream analysis, including EDA (exploratory data analysis) and modeling (machine learning).\ncrop_yields %\u0026gt;% count(Year) ## # A tibble: 58 x 2 ## Year n ## \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 1961 209 ## 2 1962 209 ## 3 1963 209 ## 4 1964 209 ## 5 1965 209 ## 6 1966 211 ## 7 1967 211 ## 8 1968 213 ## 9 1969 213 ## 10 1970 213 ## # … with 48 more rows # Use janitor package to clean column names and pivot_longer from tidyr to tidy the data. crop_yield_tidy \u0026lt;- crop_yields %\u0026gt;% janitor::clean_names() %\u0026gt;% rename_all(str_remove, \u0026quot;_tonnes.*\u0026quot;) %\u0026gt;% rename(country = entity) %\u0026gt;% pivot_longer(wheat:bananas, names_to = \u0026#39;crop\u0026#39;, values_to = \u0026#39;yield_hectare\u0026#39;) %\u0026gt;% drop_na(yield_hectare) kable(head(crop_yield_tidy, n = 10))   country code year crop yield_hectare    Afghanistan AFG 1961 wheat 1.0220  Afghanistan AFG 1961 rice 1.5190  Afghanistan AFG 1961 maize 1.4000  Afghanistan AFG 1961 potatoes 8.6667  Afghanistan AFG 1961 barley 1.0800  Afghanistan AFG 1962 wheat 0.9735  Afghanistan AFG 1962 rice 1.5190  Afghanistan AFG 1962 maize 1.4000  Afghanistan AFG 1962 potatoes 7.6667  Afghanistan AFG 1962 barley 1.0800    # crop_yield_tidy %\u0026gt;% # summary() # # crop_yield_tidy %\u0026gt;% # count(year, country, sort = TRUE) # # tidy_select \u0026lt;- crop_yield_tidy %\u0026gt;% # count(country, sort = TRUE) %\u0026gt;% # filter(n \u0026gt;=500) # # crop_yield_tidy %\u0026gt;% # summarize(max(year)- min(year)) #57 years of recorded data # # crop_yield_tidy %\u0026gt;% # count(year, crop, sort = T) # # crop_yield_tidy %\u0026gt;% # filter(country == \u0026#39;United States\u0026#39;) %\u0026gt;% # count(crop)  Visual analysis Now that we have the data in tidy format, let’s see what we can learn from it. We want to look at crop production by country but there are too many countries to look at in a single plot. slice_sample() can be used to randomly select a subset of the total countries. We will use the results to visualize a subset of the countries with the idea that this will help us get a feel for relationships in the data. For more refined control of the country selection, we could incorporate the code into a Shiny dashboard with user conntrolled selection inputs.\n# Randomly select 9 country names # set.seed(1014) if you want the same 9 countries to be selected each time country_random \u0026lt;- crop_yield_tidy %\u0026gt;% select(country) %\u0026gt;% distinct() %\u0026gt;% slice_sample(n = 9) %\u0026gt;% pull() # another option would be to set the code equal to a set selection of countries: E.g., countries \u0026lt;- c(\u0026#39;GUM\u0026#39;, \u0026#39;IND\u0026#39;, \u0026#39;YEM\u0026#39;, \u0026#39;NAM\u0026#39;, \u0026#39;URY\u0026#39;, \u0026#39;USA\u0026#39;) # Plot crop yield per hectare. library(tidytext) usa_col_plot \u0026lt;- crop_yield_tidy %\u0026gt;% filter(country == \u0026#39;United States\u0026#39;) %\u0026gt;% mutate(crop = fct_reorder(crop, yield_hectare)) %\u0026gt;% ggplot(aes(yield_hectare, crop, fill = crop)) + geom_col() + facet_wrap(~country, scales = \u0026#39;free_y\u0026#39;) + theme(legend.position = \u0026#39;none\u0026#39;) + labs( title = \u0026#39;Crop Yield USA\u0026#39;, y = \u0026#39;Crop\u0026#39;, x = \u0026#39;tonnes per hectare\u0026#39; ) usa_col_plot column_plot \u0026lt;- crop_yield_tidy %\u0026gt;% filter(country == country_random) %\u0026gt;% mutate(crop = reorder_within(crop, yield_hectare, country)) %\u0026gt;% ggplot(aes(yield_hectare, crop, fill = crop)) + geom_col() + scale_y_reordered() + facet_wrap(~country, scales = \u0026#39;free_y\u0026#39;) + theme(legend.position = \u0026#39;none\u0026#39;) + labs( title = \u0026#39;Crop Yield\u0026#39;, y = \u0026#39;Crop\u0026#39;, x = \u0026#39;yield per hectare\u0026#39; ) column_plot Figure 1. This column plot shows the crop on the y-axis, yield on the x-axis and is faceted by country.\n# Plot crop yield per hectare per year. line_plot \u0026lt;- crop_yield_tidy %\u0026gt;% filter(year \u0026gt;= 2000, country == country_random) %\u0026gt;% mutate(crop = fct_reorder(crop, yield_hectare)) %\u0026gt;% ggplot(aes(year, yield_hectare, color = crop)) + geom_line() + facet_wrap(~country, scales = \u0026#39;free_y\u0026#39;) + labs( y = \u0026#39;yield per hectare\u0026#39;, title = \u0026#39;Crop Yield\u0026#39; ) line_plot # Plot crop yield per hectare per year. box_plot \u0026lt;- crop_yield_tidy %\u0026gt;% filter(year \u0026gt;= 2000, country == country_random) %\u0026gt;% mutate(crop = fct_reorder(crop, yield_hectare)) %\u0026gt;% ggplot(aes(yield_hectare, crop, color = crop)) + geom_boxplot() + theme(legend.position = \u0026#39;none\u0026#39;) + facet_wrap(~country, scales = \u0026#39;free\u0026#39;) + labs( x = \u0026#39;Yield\u0026#39;, title = \u0026#39;Crop Yield\u0026#39;, y = \u0026#39;\u0026#39; ) box_plot  ","date":1599091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603152000,"objectID":"7ab900960e472a8bde7aa822b075d5b9","permalink":"/post/hello-tidyverse/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/post/hello-tidyverse/","section":"post","summary":"Data wrangling and visualization: insights into data analysis with the tidyverse","tags":[],"title":"Hello Tidyverse and Tidymodels","type":"post"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"See some of the projects I have worked on","tags":null,"title":"Projects","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"/about/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"A little more about me and how to get in touch","tags":null,"title":"Resume","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"65de3680a280f6bf29dc34fe1adad5a6","permalink":"/talks/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/talks/","section":"","summary":"Upcoming and recent talks / workshops","tags":null,"title":"Talks \u0026 Workshops","type":"widget_page"},{"authors":null,"categories":null,"content":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"53e892b8b41cc4caece1cfd5ef21d6e7","permalink":"/license/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/license/","section":"","summary":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","tags":null,"title":"LICENSE: CC-BY-SA","type":"page"}]